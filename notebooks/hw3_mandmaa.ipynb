{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Homework 3\n","The goal of the homework was to achieve at least 55% accuracy for image classification on the TinyImagenet-200 dataset. \n","\n","Main part of the code is based on the https://github.com/papkov/tinyimagenet.git repository.\n","\n","The notebook was run on kaggle.com because it is about two times faster than Colab and it is more transparent about the limitations of the environment."]},{"cell_type":"markdown","metadata":{},"source":["## Initialize runtime"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T07:41:16.825792Z","iopub.status.busy":"2021-11-26T07:41:16.825474Z","iopub.status.idle":"2021-11-26T07:41:17.569840Z","shell.execute_reply":"2021-11-26T07:41:17.568959Z","shell.execute_reply.started":"2021-11-26T07:41:16.825758Z"},"id":"95i-KWcv3kb-","outputId":"81a8d3c6-1283-46e8-fdd9-3f9ac890495f","trusted":true},"outputs":[],"source":["!git clone https://github.com/svnrk/tinyimagenet.git"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-26T07:42:51.515165Z","iopub.status.busy":"2021-11-26T07:42:51.514493Z","iopub.status.idle":"2021-11-26T07:43:07.147910Z","shell.execute_reply":"2021-11-26T07:43:07.147008Z","shell.execute_reply.started":"2021-11-26T07:42:51.515122Z"},"id":"ieD89qlT29VX","jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n","!unzip tiny-imagenet-200.zip -d /kaggle/working/tinyimagenet/data\n","#!rm tiny-imagenet-200.zip"]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-26T07:40:48.488112Z","iopub.status.busy":"2021-11-26T07:40:48.487826Z","iopub.status.idle":"2021-11-26T07:41:03.029666Z","shell.execute_reply":"2021-11-26T07:41:03.028799Z","shell.execute_reply.started":"2021-11-26T07:40:48.488076Z"},"id":"IMQNjED93teB","jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["\n","!pip install hydra-core omegaconf\n","!pip install -U albumentations"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T07:47:53.903291Z","iopub.status.busy":"2021-11-26T07:47:53.903000Z","iopub.status.idle":"2021-11-26T07:47:53.910130Z","shell.execute_reply":"2021-11-26T07:47:53.909178Z","shell.execute_reply.started":"2021-11-26T07:47:53.903256Z"},"id":"FHmhx5ILU_f0","outputId":"7b7336cf-dfab-40d7-9dbe-02b810dfc3bc","trusted":true},"outputs":[],"source":["%cd tinyimagenet"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T07:48:06.939650Z","iopub.status.busy":"2021-11-26T07:48:06.939369Z","iopub.status.idle":"2021-11-26T07:48:09.090755Z","shell.execute_reply":"2021-11-26T07:48:09.089977Z","shell.execute_reply.started":"2021-11-26T07:48:06.939602Z"},"id":"RlSGGVr2WJn6","trusted":true},"outputs":[],"source":["import sys\n","import os\n","sys.path.insert(0, \".\")\n","\n","from modules import dataset\n","# you can call reload(module) if you update the source code e.g. with `git pull`\n","from importlib import reload\n","\n","import albumentations as albu\n","import matplotlib.pyplot as plt\n","from omegaconf import OmegaConf, DictConfig\n","from pathlib import Path"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T07:48:11.881203Z","iopub.status.busy":"2021-11-26T07:48:11.880507Z","iopub.status.idle":"2021-11-26T07:48:12.900708Z","shell.execute_reply":"2021-11-26T07:48:12.899972Z","shell.execute_reply.started":"2021-11-26T07:48:11.881164Z"},"id":"KEz78Ek4WbDB","trusted":true},"outputs":[],"source":["reload(dataset)\n","cfg = OmegaConf.load('config/data/tinyimagenet.yaml')\n","\n","data_root = Path(cfg.root)\n","train_path = data_root / cfg.train\n","val_path = data_root / cfg.val\n","\n","train_dataset = dataset.TinyImagenetDataset(train_path, cfg, None)\n","val_dataset = dataset.TinyImagenetDataset(val_path, cfg, None)"]},{"cell_type":"markdown","metadata":{},"source":["## Display data example"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T07:48:16.236618Z","iopub.status.busy":"2021-11-26T07:48:16.236139Z","iopub.status.idle":"2021-11-26T07:48:16.835812Z","shell.execute_reply":"2021-11-26T07:48:16.835097Z","shell.execute_reply.started":"2021-11-26T07:48:16.236578Z"},"id":"QGtzA-E2Wg1x","trusted":true},"outputs":[],"source":["def clean_show(ax):\n","    \"Show plt figure without axes in tight layout\"\n","    plt.setp(ax, xticks=[], yticks=[])\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def show_examples(dataset, n_examples=10, s=2):\n","    fig, axes = plt.subplots(ncols=n_examples, figsize=(s*n_examples, s))\n","    for i, (ax, item) in enumerate(zip(axes, dataset)):\n","        ax.imshow(item.image)\n","        ax.set_title(item.id)\n","        ax.set_xlabel(item.label)\n","    clean_show(axes)\n","\n","show_examples(train_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["## Augmentation\n","The changes to the augmentaion were based on the article https://medium.com/@lokeshpara17/tiny-imagenet-using-pytorch-42a3f2ee3c9d\n","0. input image 64x64\n","1. Pad to size 72x72\n","2. RandomCrop to size 64x64\n","3. Rotate to limit 15deg\n","4. Horizontal flip \n","5. RandomGamma \n","6. RandomContrast\n","7. RandomBrightness\n","8. Cutout hole (8x8)"]},{"cell_type":"markdown","metadata":{},"source":["## Training\n"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet18_v2\n","\n","At first ResNet18_v2 was used to complete the task. Since the evaluation code did not work on custom networks, the result on this work are not complete and other options were looked at. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOXTjXm94Muc","trusted":true},"outputs":[],"source":["# Command for training custom ResNet18_v2\n","#!python train.py train.epochs=40 train.batch_size=256"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet50\n","For the second try torchvisions ResNet50 was used. The \"official\" network allowed evauation and from that in showed that the results were not good enough."]},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-26T07:51:00.696612Z","iopub.status.busy":"2021-11-26T07:51:00.696334Z","iopub.status.idle":"2021-11-26T08:37:28.237175Z","shell.execute_reply":"2021-11-26T08:37:28.236276Z","shell.execute_reply.started":"2021-11-26T07:51:00.696581Z"},"id":"R6YNh2uf592u","jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# Command for training torchvision ResNet50\n","#!python train.py train.epochs=20 train.batch_size=256 model.module=torchvision model.arch=resnet50"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet50 pretrained\n","\n","For the third try the pretrained version of ResNet50 network was used. The pretraining was done on the larger Imagenet dataset. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Command for training ResNet50 pretrained on Imagnet\n","#!python train.py train.epochs=20 train.batch_size=256 model.module=torchvision model.arch=resnet50 model.pretrained=true"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download results from runtime\n","#!zip -r /kaggle/working/results.zip /kaggle/working/tinyimagenet/results"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import argparse\n","import logging\n","from typing import Tuple, Union\n","\n","#import albumentations as albu\n","import numpy as np\n","import torch\n","from hydra.utils import instantiate, to_absolute_path\n","from omegaconf import OmegaConf\n","from torch.nn.modules import loss\n","from torch.utils.data import DataLoader\n","\n","from modules.dataset import DatasetItem, TinyImagenetDataset\n","from modules.runner import test\n","from modules.transform import to_tensor_normalize\n","from torchvision import models\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:43:09.594580Z","iopub.status.busy":"2021-11-26T10:43:09.594295Z","iopub.status.idle":"2021-11-26T10:43:09.618841Z","shell.execute_reply":"2021-11-26T10:43:09.617929Z","shell.execute_reply.started":"2021-11-26T10:43:09.594547Z"},"trusted":true},"outputs":[],"source":["def evaluate_model(\n","    results_root: Union[str, Path], data_part: str = \"val\", device: str = \"cuda\"\n",") -> Tuple[float, float, np.ndarray]:\n","    \"\"\"\n","    The main training function\n","    :param results_root: path to results folder\n","    :param data_part: {train, val, test} partition to evaluate model on\n","    :param device: {cuda, cpu}\n","    :return: None\n","    \"\"\"\n","    results_root = Path(results_root)\n","    logging.basicConfig(\n","        filename=results_root / f\"{data_part}.log\", level=logging.NOTSET\n","    )\n","    # Setup logging and show config ьфлу\n","    log = logging.getLogger(__name__)\n","    if not log.handlers:\n","        log.addHandler(logging.StreamHandler())\n","\n","    cfg_path = results_root / \".hydra/config.yaml\"\n","    log.info(f\"Read config from {cfg_path}\")\n","\n","    cfg = OmegaConf.load(str(cfg_path))\n","    log.info(f\"Config:\\n{OmegaConf.to_yaml(cfg)}\")\n","\n","    # Specify results paths from config\n","    checkpoint_path = results_root / cfg.results.checkpoints.root\n","    checkpoint_path /= f\"{cfg.results.checkpoints.name}.pth\"\n","\n","    # Data\n","    # Specify data paths from config\n","    data_root = Path(cfg.data.root)\n","    test_path = data_root / data_part\n","\n","    # Check if dataset is available\n","    log.info(f\"Looking for dataset in {str(data_root)}\")\n","    if not data_root.exists():\n","        log.error(\n","            \"Folder not found. Terminating. \"\n","            \"See README.md for data downloading details.\"\n","        )\n","        raise FileNotFoundError\n","\n","    valid_transform = to_tensor_normalize()\n","    if \"augmentation\" in cfg:\n","        pre_transform = albu.load(\n","            to_absolute_path(cfg.augmentation.pre), data_format=\"yaml\"\n","        )\n","        post_transform = albu.load(\n","            to_absolute_path(cfg.augmentation.post), data_format=\"yaml\"\n","        )\n","        valid_transform = albu.Compose([pre_transform, post_transform])\n","\n","    test_dataset = TinyImagenetDataset(test_path, cfg.data, valid_transform)\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=cfg.train.batch_size,\n","        shuffle=False,\n","        collate_fn=DatasetItem.collate,\n","        num_workers=cfg.train.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    log.info(\n","        f\"Created test dataset ({len(test_dataset)}) \"\n","        f\"and loader ({len(test_loader)}): \"\n","        f\"batch size {cfg.train.batch_size}, \"\n","        f\"num workers {cfg.train.num_workers}\"\n","    )\n","\n","    loss_function = loss.CrossEntropyLoss()\n","    #model = instantiate(cfg.model)\n","    model = models.resnet50()\n","    model.fc = nn.Linear(2048, 200)\n","    try:\n","        \n","        model.load_state_dict(torch.load(checkpoint_path, map_location=\"cpu\"))\n","    except RuntimeError as e:\n","        log.error(\"Failed loading state dict\")\n","        raise e\n","    except FileNotFoundError as e:\n","        log.error(\"Checkpoint not found\")\n","        raise e\n","    log.info(f\"Loaded model from {checkpoint_path}\")\n","    device = (\n","            torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","        )\n","    test_loss, test_acc, test_outputs = test(\n","        model, device, test_loader, loss_function, 0, log\n","    )\n","    log.info(f\"Loss {test_loss}, acc {test_acc}\")\n","    log.info(f\"Outputs:\\n{test_outputs.shape}\\n{test_outputs[:5, :5]}\")\n","    logging.shutdown()\n","    return test_loss, test_acc, test_outputs\n","\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"-r\", \"--results\", help=\"results root\", type=str)\n","  #  parser.add_argument(\n","   #     \"-p\",\n","   #     \"--data_part\",\n","   #     default=\"val\",\n","   #     choices=[\"train\", \"val\", \"test\"],\n","   #     help=\"data partition to evaluate on\",\n","   #     type=str,\n","   # )\n","    #parser.add_argument(\n","    #    \"-d\", \"--device\", default=\"cuda\", choices=[\"cuda\", \"cpu\"], type=str\n","    #)\n","    args = parser.parse_args()\n","    test_loss, test_acc, test_outputs = evaluate_model(\n","        args.results\n","    )"]},{"cell_type":"code","execution_count":131,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["test_loss_v1, test_acc_v1, test_outputs_v1 = evaluate_model('results/torchvision.resnet50/2021-11-26_07-51-03')"]},{"cell_type":"code","execution_count":79,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2021-11-26T10:09:33.482267Z","iopub.status.busy":"2021-11-26T10:09:33.481724Z","iopub.status.idle":"2021-11-26T10:09:48.236884Z","shell.execute_reply":"2021-11-26T10:09:48.235879Z","shell.execute_reply.started":"2021-11-26T10:09:33.482232Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["test_loss_v2, test_acc_v2, test_outputs_v2 = evaluate_model('results/torchvision.resnet50/2021-11-26_09-09-36')"]},{"cell_type":"markdown","metadata":{},"source":["## Results\n","\n","For two of the tries evauation was used and the result follow. The tensorboard outputs for three networks are shown in graph below. It seem that two of the network were good enough to best the accuracy limit of 55%."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import seaborn as sns\n","from scipy.special import softmax\n","from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n","from functools import reduce\n","import pandas as pd"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:11:23.790551Z","iopub.status.busy":"2021-11-26T10:11:23.790272Z","iopub.status.idle":"2021-11-26T10:11:23.795960Z","shell.execute_reply":"2021-11-26T10:11:23.795204Z","shell.execute_reply.started":"2021-11-26T10:11:23.790522Z"},"trusted":true},"outputs":[],"source":["print('ResNet50 acc:', test_acc_v1)\n","print('ResNet50 pretrained acc:', test_acc_v2)"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:30:23.289379Z","iopub.status.busy":"2021-11-26T10:30:23.289104Z","iopub.status.idle":"2021-11-26T10:30:23.346086Z","shell.execute_reply":"2021-11-26T10:30:23.345385Z","shell.execute_reply.started":"2021-11-26T10:30:23.289349Z"},"trusted":true},"outputs":[],"source":["def read_tensorboard(path, tags=['train_acc', 'test_acc']):\n","    ea =  EventAccumulator(path)\n","    ea.Reload()\n","    dfs = []\n","    for tag in tags:\n","        df = pd.DataFrame(ea.Scalars(tag)).drop('wall_time', 1)\n","        df.columns = ['step', tag]\n","        dfs.append(df)\n","    dfs = reduce(lambda left, right: pd.merge(left, right, on='step'), dfs)\n","    return dfs"]},{"cell_type":"code","execution_count":107,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:33:02.261795Z","iopub.status.busy":"2021-11-26T10:33:02.261303Z","iopub.status.idle":"2021-11-26T10:33:02.311689Z","shell.execute_reply":"2021-11-26T10:33:02.310674Z","shell.execute_reply.started":"2021-11-26T10:33:02.261751Z"},"trusted":true},"outputs":[],"source":["training_v1 = read_tensorboard('/kaggle/working/tinyimagenet/results/torchvision.resnet50/2021-11-26_07-51-03/tensorboard/events.out.tfevents.1637913071.54e8db379f4c.558.0')\n","training_v2 = read_tensorboard('/kaggle/working/tinyimagenet/results/torchvision.resnet50/2021-11-26_09-09-36/tensorboard/events.out.tfevents.1637917781.54e8db379f4c.4350.0')\n","training_v3 = read_tensorboard('/kaggle/working/tinyimagenet/results/models.resnet18/2021-11-19_16-35-06/tensorboard/events.out.tfevents.1637339715.d3a5626814b4.1626.0')\n","\n","training = pd.concat([\n","    training_v1.assign(model='resnet50'),\n","    training_v2.assign(model='resnet50_pre'),\n","    training_v3.assign(model='resnet18_v2')\n","])\n","training = training.melt(id_vars=['step', 'model'], value_name='accuracy', var_name='split')\n","\n","training.split = training.split.str.replace('_acc', '')\n","\n","training.head()"]},{"cell_type":"code","execution_count":129,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:40:42.526491Z","iopub.status.busy":"2021-11-26T10:40:42.526237Z","iopub.status.idle":"2021-11-26T10:40:42.839337Z","shell.execute_reply":"2021-11-26T10:40:42.838664Z","shell.execute_reply.started":"2021-11-26T10:40:42.526463Z"},"trusted":true},"outputs":[],"source":["sns.lineplot(x='step', y='accuracy', hue='model', style='split', data=training)\n","plt.plot([0, 40], [55, 55], label=\"55%\", color=\"red\")\n","plt.show()"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:34:15.400822Z","iopub.status.busy":"2021-11-26T10:34:15.400297Z","iopub.status.idle":"2021-11-26T10:34:15.413378Z","shell.execute_reply":"2021-11-26T10:34:15.412699Z","shell.execute_reply.started":"2021-11-26T10:34:15.400775Z"},"trusted":true},"outputs":[],"source":["cfg = OmegaConf.load('config/data/tinyimagenet.yaml')\n","print(OmegaConf.to_yaml(cfg))"]},{"cell_type":"code","execution_count":113,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:34:52.550259Z","iopub.status.busy":"2021-11-26T10:34:52.549996Z","iopub.status.idle":"2021-11-26T10:34:52.789695Z","shell.execute_reply":"2021-11-26T10:34:52.788873Z","shell.execute_reply.started":"2021-11-26T10:34:52.550231Z"},"trusted":true},"outputs":[],"source":["data_root = Path(cfg.root)\n","val_path = data_root / cfg.val\n","val_dataset = dataset.TinyImagenetDataset(val_path, cfg, None)"]},{"cell_type":"code","execution_count":115,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:35:41.390708Z","iopub.status.busy":"2021-11-26T10:35:41.390437Z","iopub.status.idle":"2021-11-26T10:35:41.432654Z","shell.execute_reply":"2021-11-26T10:35:41.431739Z","shell.execute_reply.started":"2021-11-26T10:35:41.390677Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","\n","cm_v1 = confusion_matrix(y_true=val_dataset._df.label,\n","                         y_pred=np.argmax(test_outputs_v1, 1))\n","\n","cm_v2 = confusion_matrix(y_true=val_dataset._df.label,\n","                         y_pred=np.argmax(test_outputs_v2, 1))"]},{"cell_type":"code","execution_count":132,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T11:06:47.997447Z","iopub.status.busy":"2021-11-26T11:06:47.997156Z","iopub.status.idle":"2021-11-26T11:06:49.314257Z","shell.execute_reply":"2021-11-26T11:06:49.313476Z","shell.execute_reply.started":"2021-11-26T11:06:47.997408Z"},"trusted":true},"outputs":[],"source":["fig, axes = plt.subplots(ncols=2, figsize=(9, 4))\n","for cm, ax, t in zip([cm_v1, cm_v2], axes, ['Resnet50', 'Resnet50_pretrained']):\n","    sns.heatmap(cm, ax=ax, vmax=50)\n","    ax.set_title(t)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":118,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:36:51.384231Z","iopub.status.busy":"2021-11-26T10:36:51.383591Z","iopub.status.idle":"2021-11-26T10:36:51.408398Z","shell.execute_reply":"2021-11-26T10:36:51.407381Z","shell.execute_reply.started":"2021-11-26T10:36:51.384186Z"},"trusted":true},"outputs":[],"source":["test_pred_v2 = softmax(test_outputs_v2, 1)\n","sorted_by_correct_score = np.argsort(test_pred_v2[np.arange(len(test_pred_v2)), val_dataset._df.label.tolist()])\n","sorted_by_correct_score[:5]"]},{"cell_type":"code","execution_count":120,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:37:40.015539Z","iopub.status.busy":"2021-11-26T10:37:40.015278Z","iopub.status.idle":"2021-11-26T10:37:40.346410Z","shell.execute_reply":"2021-11-26T10:37:40.345542Z","shell.execute_reply.started":"2021-11-26T10:37:40.015509Z"},"trusted":true},"outputs":[],"source":["folders_to_num, val_labels = dataset.get_labels_mapping(cfg)\n","\n","class_labels = pd.read_csv(data_root / cfg.train_labels, sep='\\t', header=None)\n","class_labels[0] = class_labels[0].apply(lambda x: int(folders_to_num[x]) if x in folders_to_num else None)\n","class_labels = class_labels.dropna()\n","\n","class_labels_dict = {int(r[0]): r[1].split(',')[0] for i, r in class_labels.iterrows()}"]},{"cell_type":"code","execution_count":121,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:37:51.422302Z","iopub.status.busy":"2021-11-26T10:37:51.421589Z","iopub.status.idle":"2021-11-26T10:37:51.428809Z","shell.execute_reply":"2021-11-26T10:37:51.428092Z","shell.execute_reply.started":"2021-11-26T10:37:51.422268Z"},"trusted":true},"outputs":[],"source":["def clean_show(ax):\n","    \"Show plt figure without axes in tight layout\"\n","    plt.setp(ax, xticks=[], yticks=[])\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":122,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:38:07.195190Z","iopub.status.busy":"2021-11-26T10:38:07.194922Z","iopub.status.idle":"2021-11-26T10:38:07.201973Z","shell.execute_reply":"2021-11-26T10:38:07.200911Z","shell.execute_reply.started":"2021-11-26T10:38:07.195160Z"},"trusted":true},"outputs":[],"source":["def show_examples(dataset, ids, predictions, s=2):\n","    n_examples = len(ids)\n","    fig, axes = plt.subplots(ncols=n_examples, figsize=(s*n_examples, s))\n","    for ax, i in zip(axes, ids):\n","        item = dataset[i]\n","        ax.imshow(item.image)\n","        ax.set_title(item.id)\n","        pred_label = np.argmax(predictions[i])\n","        label = f\"T: {class_labels_dict[item.label]} ({predictions[i, item.label]:.2e})\\n\" \\\n","                f\"P: {class_labels_dict[pred_label]} ({predictions[i, pred_label]:.2e})\"\n","        ax.set_xlabel(label)\n","    clean_show(axes)"]},{"cell_type":"code","execution_count":123,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:38:19.375740Z","iopub.status.busy":"2021-11-26T10:38:19.375457Z","iopub.status.idle":"2021-11-26T10:38:19.816183Z","shell.execute_reply":"2021-11-26T10:38:19.815478Z","shell.execute_reply.started":"2021-11-26T10:38:19.375710Z"},"trusted":true},"outputs":[],"source":["show_examples(val_dataset, sorted_by_correct_score[:7], test_pred_v2)"]},{"cell_type":"code","execution_count":124,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:39:06.917912Z","iopub.status.busy":"2021-11-26T10:39:06.917247Z","iopub.status.idle":"2021-11-26T10:39:06.923711Z","shell.execute_reply":"2021-11-26T10:39:06.922682Z","shell.execute_reply.started":"2021-11-26T10:39:06.917872Z"},"trusted":true},"outputs":[],"source":["def class_accuracy(predictions, labels):\n","    accuracy = {}\n","    for lab in np.unique(labels):\n","        mask = labels == lab\n","        accuracy[class_labels_dict[lab]] = np.mean(np.argmax(predictions, 1)[mask] == labels[mask])\n","    return pd.DataFrame(accuracy, index=['accuracy']).T"]},{"cell_type":"code","execution_count":125,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:39:17.511283Z","iopub.status.busy":"2021-11-26T10:39:17.510475Z","iopub.status.idle":"2021-11-26T10:39:17.999511Z","shell.execute_reply":"2021-11-26T10:39:17.998778Z","shell.execute_reply.started":"2021-11-26T10:39:17.511240Z"},"trusted":true},"outputs":[],"source":["class_accuracy_df = class_accuracy(test_pred_v2, val_dataset._df.label)"]},{"cell_type":"code","execution_count":126,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:39:29.874315Z","iopub.status.busy":"2021-11-26T10:39:29.873616Z","iopub.status.idle":"2021-11-26T10:39:29.884369Z","shell.execute_reply":"2021-11-26T10:39:29.883617Z","shell.execute_reply.started":"2021-11-26T10:39:29.874279Z"},"trusted":true},"outputs":[],"source":["class_accuracy_df.sort_values('accuracy').head(5)"]},{"cell_type":"code","execution_count":127,"metadata":{"execution":{"iopub.execute_input":"2021-11-26T10:39:51.456584Z","iopub.status.busy":"2021-11-26T10:39:51.456259Z","iopub.status.idle":"2021-11-26T10:39:51.470753Z","shell.execute_reply":"2021-11-26T10:39:51.469561Z","shell.execute_reply.started":"2021-11-26T10:39:51.456548Z"},"trusted":true},"outputs":[],"source":["class_accuracy_df.sort_values('accuracy', ascending=False).head(5)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
